#!/usr/bin/python

# pircam, 2019 by Niklaus Fankhauser
# Motion detection sensor triggered capture and combination of MJPEG video and audio from D-Link network cameras.

import os, sys, time, threading, urllib, subprocess, xmpp, sqlite3
from tinkerforge.ip_connection import IPConnection
from tinkerforge.bricklet_motion_detector import BrickletMotionDetector
from tinkerforge.bricklet_motion_detector_v2 import BrickletMotionDetectorV2
if os.fork(): sys.exit() # Run as daemon

# Globals
config_file = '/opt/pircam_config.txt'
current_video_thread, current_audio_thread = {}, {} # One thread per camera, for video and audio
current_convert_thread = None # Only one convert thread, for video and audio
video_queue, audio_queue = {}, {} # One queue per camera
sensorAPI = {} # Motion detector dictionary
cbFuns = {} # Callback function dictionary
ipcon = {} # TCP/IP connections

def load_config(fn, section):
	"""Load specified section of config file into dictionary."""
	cdict, current_section = {}, ''
	for i in open(fn):
		if not i.strip(): continue
		isp = i.strip().split('=')
		if len(isp) == 1:
			title = isp[0].strip()
			if title in ['GLOBAL', 'CAMERA', 'SENSOR']: current_section = title
			else: device = title
		if current_section != section: continue
		if len(isp) == 2:
			key, value = isp[0].strip(), isp[1].strip()
			if current_section == 'GLOBAL': 
				cdict[key] = value
			else:
				if not cdict.has_key(device): cdict[device] = {}
				cdict[device][key] = value
	return cdict

def logg(x):
	"""Writes message and formated timestamp to logfile."""
	x = '%s: %s' % (time.strftime('%Y-%m-%d %H:%M:%S'), x)
	open(config['logfile'], 'a').write(x + '\n')
 
def download_mjpeg(CAMID):
	"""Download specified size from MJPEG stream by HTTP using urllib and append filename to video-queue."""
	global video_queue
	ofn = '%s/%s_mjpeg/%s.mjpeg' % (config['data_dir'], CAMID, time.strftime('%Y%m%d_%H%M%S'))
	try:
		stream = urllib.urlopen(cameras[CAMID]['mjpeg']).read(int(cameras[CAMID]['read']))
	except:
		logg('%s: Video download error!' % CAMID)
		return
	open(ofn, 'w').write(stream)
	if not video_queue.has_key(CAMID): video_queue[CAMID] = []
	video_queue[CAMID].append(ofn)
	logg('%s: Downloaded %2.2f MB to %s' % (CAMID, len(stream)/1024.0/1024.0, ofn))
 
def log_and_run(cmd):
	"""Run command using subprocess.call and only log in case of error."""
	rcode = subprocess.call(cmd)
	if rcode > 0: logg('%s (%d)' % (' '.join(cmd), rcode))
 
def download_audio(CAMID):
	"""Download AAC audio in a MP4 container from RTSP using ffmpeg and add filename to audio-queue."""
	global audio_queue
	ofn = '%s/%s_mp4/%s.mp4' % (config['data_dir'], CAMID, time.strftime('%Y%m%d_%H%M%S'))
	cmd = 'ffmpeg', '-hide_banner', '-i', cameras[CAMID]['audio'], '-vn', '-acodec', 'copy', '-t', config['rec_sec'], ofn
	log_and_run(cmd)
	if not os.path.isfile(ofn):
		logg('%s: Audio download failed!' % CAMID)
		return
	if not audio_queue.has_key(CAMID): audio_queue[CAMID] = []
	audio_queue[CAMID].append(ofn)
	logg('%s: Downloaded %2.2f KB to %s' % (CAMID, os.stat(ofn).st_size/1024.0, ofn))
 
def extract_first_jpeg(mjpeg_data):
	"""Exctracts first image from MJPEG stream."""
	header = mjpeg_data.split('\r\n\r\n')[0]
	if not 'Length: ' in header: return ''
	content_length = header.split('Length: ')[1].split('\r\n')[0].strip()
	try: content_length = int(content_length)
	except: return ''
	data_start = len(header) + 4
	if len(mjpeg_data) <= data_start + content_length: return ''
	return mjpeg_data[data_start:(data_start + content_length)]
 
def upload_to_webserver(fn, remote_path):
	"""Run a rsync command to upload a file to a path on the webserver."""
	cmd = 'rsync', fn, '%s:%s/' % (config['webserver'], remote_path)
	log_and_run(cmd)

def filebase(x):
	"""Returns filename without path and extension."""
	return os.path.splitext(os.path.basename(x))[0]

def timeFormat(x):
	"""Convert YYYYMMDD_HHMMSS to YYYY-MM-DD_HH:MM:SS"""
	return time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(filebase(x), "%Y%m%d_%H%M%S"))

def get_rate(mfn, ofn):
	return int(100 * float(os.stat(ofn).st_size) / float(os.stat(mfn).st_size))

def rate_to_db(fn, rate):
	db = sqlite3.connect(config['db_fn'])
	dbc = db.cursor()
	fn2 = fn.replace(config['data_dir'] + '/', '')
	dbc.execute('INSERT INTO files (fn, rate) VALUES (?,?)',(fn2, rate))
	db.commit()
	db.close()

def rate_from_db(fn):
	db = sqlite3.connect(config['db_fn'])
	dbc = db.cursor()
	fn2 = fn.replace(config['data_dir'] + '/', '')
	dbc.execute('SELECT rate FROM files WHERE fn = ?', (fn2,))
	r = dbc.fetchone()
	db.close()
	if not r: return 0
	return r[0]

def index_element(fpath):
	"""Generates variables required for an element in photoswipe."""
	src = fpath.replace(config['data_dir'], '')
	w, h = config['size_x'], config['size_y']
	video = src.replace('jpg', 'ogg').strip('/')
	title = '%s (%d%%)' % (timeFormat(fpath), rate_from_db(video))
	pid = filebase(fpath)
	return "{src:'%s', w:%s, h:%s, title:'%s', video:'%s', pid:'%s'}" % (src, w, h, title, video, pid)

def generate_index_page():
	"""Generates HTML page for the numLast recorded videos with photoswipe user interface.""" 
	path = lambda x : '%s/%s' % (config['data_dir'], x)
	ftup = [ (f, '%s/%s' % (path(c), f)) for c in cameras.keys() for f in os.listdir(path(c)) if f.endswith('jpg') ]
	image_paths =  [ fpath for (fn, fpath) in sorted(ftup) ]
	elemlist = [ index_element(fpath) for fpath in reversed(image_paths) ]
	photoswipe_script = 'var items = [\n%s\n];\n' % ',\n'.join(elemlist[:int(config['numLast'])])
	scriptPath = '%s/pircam.js' % config['data_dir']
	open(scriptPath, 'w').write(photoswipe_script)

def run_converter(CAMID):
	"""Matches audio to video and combines using ffmpeg, also comnverting to ogg theora/vorbis. 
	Extracts first image, creates the index-page and uploads all to the webserver."""
	global video_queue, audio_queue, cameras
	local_video_queue, local_audio_queue = list(video_queue[CAMID]), list(audio_queue[CAMID]) # Copy queue
	video_queue[CAMID], audio_queue[CAMID] = [], [] # Empty queue
	if config['verbose'] == 'True': logg('%s: Converter started: %d video, %d audio files' % (CAMID, len(local_video_queue), len(local_audio_queue)))
	unixtime = lambda x : time.mktime(time.strptime(x, "%Y%m%d_%H%M%S"))
	audio_base = [ filebase(i) for i in local_audio_queue ]
	fps = int(cameras[CAMID]['fps'])
	for vfn in local_video_queue:
		jfn = '%s/%s/%s.jpg' % (config['data_dir'], CAMID, filebase(vfn))
		ofn = '%s/%s/%s.ogg' % (config['data_dir'], CAMID, filebase(vfn))
		mjpeg_data = open(vfn).read()
		nb_frames = mjpeg_data.count('image/jpeg')
		jpeg_data = extract_first_jpeg(mjpeg_data)
		if len(jpeg_data) == 0: 
			logg('%s: Broken video!' % CAMID)
			continue
		open(jfn, 'w').write(jpeg_data)
		if config['verbose'] == 'True': logg('%s: Image of %2.2f KB saved to %s' % (CAMID, len(jpeg_data)/1024.0, jfn))
		video_sec = nb_frames / float(fps)
		if config['verbose'] == 'True': logg('%s: %s contains %d frames -> %2.2f seconds' % (CAMID, vfn, nb_frames, video_sec))
		if nb_frames < fps:
			logg('%s: Truncated video!' % CAMID)
			continue
		if local_audio_queue:
			video_time = unixtime(filebase(vfn))
			audio_diff = [abs(unixtime(i) - video_time) for i in audio_base]
			afn = local_audio_queue[audio_diff.index(min(audio_diff))]			
			cmd = 'ffmpeg', '-hide_banner', '-y', '-r', str(fps), '-i', vfn, '-i', afn, '-codec:v', 'libtheora', '-qscale:v', '7', ofn
		else:
			cmd = 'ffmpeg', '-hide_banner', '-y', '-r', str(fps), '-i', vfn, '-codec:v', 'libtheora', '-qscale:v', '7', ofn
		log_and_run(cmd)
		if not os.path.isfile(ofn):
			logg('%s: Failed to create %s!' % (CAMID, ofn))
			continue
		logg('%s: Video of %2.2f MB created at %s' % (CAMID, os.stat(ofn).st_size/1024.0/1024.0, ofn))
		upload_to_webserver(ofn, '%s/%s' % (config['data_dir'], CAMID))
		upload_to_webserver(jfn, '%s/%s' % (config['data_dir'], CAMID))
		comp_ratio = get_rate(vfn, ofn)
		rate_to_db(ofn, comp_ratio)
	cameras[CAMID]['read'] = int(int(cameras[CAMID]['read']) * int(config['rec_sec']) / video_sec)
	if cameras[CAMID]['read'] > int(config['max_down']): cameras[CAMID]['read'] = int(config['max_down'])
	if config['verbose'] == 'True': logg('%s: New MJPEG read length is %2.2f MB' % (CAMID, cameras[CAMID]['read']/1024.0/1024.0))
	generate_index_page()
	upload_to_webserver('%s/pircam.js' % config['data_dir'], config['webRoot'])
	upload_to_webserver(config['logfile'], config['webRoot'])
	if config['verbose'] == 'True': logg('%s: Converter thread finished' % CAMID)
 
def send_jabber(CAMID):
	"""Sends a jabber message containing activated cam to the recipient specified in config."""
	jid = xmpp.protocol.JID(config['xmpp_from'])
	cl = xmpp.Client(config['xmpp_server'], debug=[])
	if not cl.connect(use_srv=False): return
	if not cl.auth(jid.getNode(), config['xmpp_pass']): return
	mid = cl.send(xmpp.protocol.Message(config['xmpp_to'], CAMID))
	if config['verbose'] == 'True': logg('%s: Jabber message id %s sent' % (CAMID, str(mid)))
 
def cb_motion_detected(CAMID):
	"""Callback function for motion detection starts threads for video/audio download, if possible."""
	global current_video_thread, current_audio_thread, audio_queue
	if os.path.isfile(config['pause_file']):
		logg('%s: Motion, paused' % CAMID)
		return
	if current_video_thread.has_key(CAMID) and current_video_thread[CAMID].isAlive(): return
	if cameras[CAMID].has_key('sun'):
		if time.strftime("%H:%M") in [ m.strip() for m in cameras[CAMID]['sun'].split(',') ]:
			logg('%s: Motion, sun' % CAMID)
			return
	current_video_thread[CAMID] = threading.Thread(target=download_mjpeg, args=[CAMID])
	current_video_thread[CAMID].start()
	logg('%s: Motion, video thread started' % CAMID)
	send_jabber(CAMID)
	if cameras[CAMID]['audio'] == 'None':
		audio_queue[CAMID] = []
		return
	if current_audio_thread.has_key(CAMID) and current_audio_thread[CAMID].isAlive(): return
	current_audio_thread[CAMID] = threading.Thread(target=download_audio, args=[CAMID])
	current_audio_thread[CAMID].start()
	logg('%s: Motion, audio thread started' % CAMID)

def is_idle():
	"""Returns True if no download or convert threads are running."""
	for CAMID in cameras.keys():
		if current_video_thread.has_key(CAMID) and current_video_thread[CAMID].isAlive(): return False
		if current_audio_thread.has_key(CAMID) and current_audio_thread[CAMID].isAlive(): return False
	if current_convert_thread != None and current_convert_thread.isAlive(): return False
	return True
 
def configure_motion_detector(uid):
	"""Turn off LED, set sensitivity and register motion detection callback function."""
	global sensorAPI, cbFuns
	sensorAPI[uid].set_status_led_config(0) # Turn off status LED (is on after bricklet reset)
	if sensors[uid]['vers'] == '2': sensorAPI[uid].set_sensitivity(sensors[uid]['sensi']) # Set sensitivity
	cbFuns[uid] = lambda : cb_motion_detected(sensors[uid]['cam']) # Create callback function
	sensorAPI[uid].register_callback(sensorAPI[uid].CALLBACK_MOTION_DETECTED, cbFuns[uid]) # Register callback function
	logg('Callback for %s at %s to %s registered' % (uid, sensors[uid]['ip'], sensors[uid]['cam']))

# Load configuration into dictionaries
sensors = load_config(config_file, 'SENSOR')
cameras = load_config(config_file, 'CAMERA')
config  = load_config(config_file, 'GLOBAL')
logg('%d sensors, %d cameras' % (len(sensors), len(cameras)))

# Create IP connections to all bricks required by the sensors
for uid in sensors.keys():
	ip = sensors[uid]['ip']
	if not ipcon.has_key(ip):
		ipcon[ip] = IPConnection() # Create IP connection
		ipcon[ip].connect(ip, int(config['brick_port'])) # Connect to brickd
	# Create motion detector sensor device object using the IP connection
	if sensors[uid]['vers'] == '1': sensorAPI[uid] = BrickletMotionDetector(uid, ipcon[ip]) 
	if sensors[uid]['vers'] == '2': sensorAPI[uid] = BrickletMotionDetectorV2(uid, ipcon[ip])
	configure_motion_detector(uid)
logg('IP connections: %d' % len(ipcon))

reconfigure_time = time.time()
while True: # Main loop
	threading.Event().wait(int(config['sleep_sec'])) # Sleep, but wake for events.
	# Start convert thread per camera, if there are videos queued and system is idle.
	for CAMID in cameras.keys():
		if not video_queue.has_key(CAMID): continue 
		if len(video_queue[CAMID]) == 0: continue
		if is_idle() or len(video_queue[CAMID]) > int(config['max_queue']):
			current_convert_thread = threading.Thread(target=run_converter, args=[CAMID])
			current_convert_thread.start()
			break
	if is_idle() and os.path.isfile(config['stop_file']): break # Terminate
	# Check for bricklet reset and reconfigure if needed (status LED on).
	if reconfigure_time + int(config['reconf_sec']) < time.time():
		for uid in sensors.keys():
			try: led_status = sensorAPI[uid].get_status_led_config()
			except:
				logg('%s: Bricklet unreachable' % uid)
				continue
			if led_status > 0:
				logg('%s: Bricklet reset' % uid)
				configure_motion_detector(uid)
		reconfigure_time = time.time()
for ip in ipcon.keys(): ipcon[ip].disconnect()
logg('Finished')
